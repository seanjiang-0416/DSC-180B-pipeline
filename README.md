# Evidence-Augmented LLMs For Misinformation Detection Winter 2024

## Project Description

This model proposes a novel approach to fact-checking by leveraging Large Language Models (LLMs) within a multi-model pipeline to provide both veracity labels and informative explanations for claims. Building upon previous research, we integrate various predictive AI models and external evidence from reliable sources to enhance the contextuality and accuracy of our predictions.

## Running Instructions

- To install the dependencies, run the following command from the root directory of the project: `pip install -r requirements.txt`
- To get the model running, run `python final_pipeline.py`

## Notes

- Make sure to run: pip install --upgrade --no-cache-dir gdown for downloading large models in drive
