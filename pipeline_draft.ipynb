{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c78c872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For sanity only\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce01c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "def scrape_site(url):\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # Extract header\n",
    "        header = soup.find(['h1']).get_text().strip()\n",
    "\n",
    "        # Extract content\n",
    "        content_tags = soup.find_all(['p'])\n",
    "        content = [tag.get_text().strip().replace('\\xa0', ' ') for tag in content_tags]\n",
    "\n",
    "        # Find the keyword 'By' to extract the author's name\n",
    "        page_text = soup.get_text()\n",
    "        match = re.search(r'\\bBy\\s+([A-Za-z\\s.,]+)', page_text)\n",
    "        authors = match.group(1).strip().replace('and', ',') if match else 'Author not found'\n",
    "        author_lst = [auth.strip() for auth in authors.split(',')]\n",
    "        return header, content, author_lst\n",
    "    else:\n",
    "        print(f\"Failed to retrieve the webpage. Status code: {response.status_code}\")\n",
    "        return None, None, None\n",
    "\n",
    "url = \"https://www.cnn.com/2024/01/17/politics/biden-ukraine-white-house-meeting/index.html\"\n",
    "header, content, authors = scrape_site(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f893cdd7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import context_veracity\n",
    "def context_veracity_score(content):\n",
    "    content_concat = \" \".join(content)\n",
    "    sent_score = context_veracity.sentiment_shift(content_concat)\n",
    "    topic_score = context_veracity.topic_shift(content_concat)\n",
    "    ner_score = context_veracity.ner_shift(content_concat)\n",
    "    context_veracity_score = context_veracity.calculate_contextual_drift(sent_score, topic_score, ner_score)\n",
    "    return context_veracity_score\n",
    "print(f\"The context veracity score of the article is {context_veracity_score(content)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac6796a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import political_bias\n",
    "def political_bias_score(content):\n",
    "    pred_labels = []\n",
    "    political_bias.download_pretrained_model()\n",
    "    for paragraph in content:\n",
    "        processed_article = political_bias.preprocess_article(header, paragraph)\n",
    "        label = political_bias.predict_label(processed_article)\n",
    "        pred_labels.append(label[0])\n",
    "    poli_bias_score = np.mean(pred_labels)\n",
    "    return poli_bias_score\n",
    "print(\"The political bias score of the article is \", political_bias_score(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2861538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# def sentiment_score(content):\n",
    "#     with open('models/sentiM.pkl', 'rb') as f:\n",
    "#         sentM = pickle.load(f)\n",
    "#     pred_labels = []\n",
    "#     for paragraph in content:\n",
    "#         label = sentM.predict_article(header, paragraph)[0]\n",
    "#         pred_labels.append(label)\n",
    "#     sent_score = np.mean(pred_labels)\n",
    "#     return sent_score\n",
    "# print(\"The sentiment score of the article is \", sentiment_score(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368168cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "def sentiment_score(content):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    distilled_student_sentiment_classifier = pipeline(\n",
    "        model=\"lxyuan/distilbert-base-multilingual-cased-sentiments-student\", \n",
    "        return_all_scores=False,\n",
    "        device=device\n",
    "    )\n",
    "    pred_labels = []\n",
    "    for paragraph in content:\n",
    "        result = distilled_student_sentiment_classifier(paragraph)[0]['label']\n",
    "        if result == 'positive':\n",
    "            pred_labels.append(0)\n",
    "        elif result == 'negative':\n",
    "            pred_labels.append(2)\n",
    "        else:\n",
    "            pred_labels.append(1)\n",
    "    return np.mean(pred_labels)\n",
    "print(\"The sentiment score of the article is \", sentiment_score(content))            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a8e8d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import html\n",
    "import re\n",
    "import credibility\n",
    "import pandas as pd\n",
    "import pickle\n",
    "def credibility_score(authors):\n",
    "    with open('models/credibility_model.pkl', 'rb') as f:\n",
    "        cred_model = pickle.load(f)\n",
    "\n",
    "    search_results = []\n",
    "    for author in authors:\n",
    "        search_results.append(credibility.search_wikipedia(author, num_results=15))\n",
    "\n",
    "    search_pd = pd.DataFrame(search_results, columns=['text'])\n",
    "    embedded_result = credibility.text_embedding(search_pd['text'])[:, :50]\n",
    "    cred_scores = cred_model.predict(embedded_result)\n",
    "    if len(cred_scores) == 1:\n",
    "        print(f'The score of {authors[0]} is {cred_scores[0]}')\n",
    "        return cred_scores[0]\n",
    "    else:\n",
    "        for i in range(len(authors)):\n",
    "            print(f'The score of {authors[i]} is {cred_scores[i]}')\n",
    "        cred_score = np.mean(cred_scores)\n",
    "        return cred_score\n",
    "print(f'The credibility score is {credibility_score(authors)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f78f1ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import text_manipulation\n",
    "def style_score(content):\n",
    "    text_manipulation.download_pretrained_model()\n",
    "    pred_labels = []\n",
    "    for paragraph in content:\n",
    "        label = text_manipulation.predict(paragraph)\n",
    "        pred_labels.append(label)\n",
    "    style_score = np.mean(pred_labels)\n",
    "    return style_score\n",
    "print(\"The text manipulation (style) score of the article is \", style_score(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96e1cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spam import SpamModel\n",
    "import pickle\n",
    "def spam_score(header):\n",
    "    with open('models/spamM.pkl', 'rb') as f:\n",
    "        spamM = pickle.load(f)\n",
    "    pred_label = spamM.predict_article(header)[0]\n",
    "    if pred_label:\n",
    "        spam_score = 1\n",
    "    else:\n",
    "        spam_score = 0\n",
    "    return spam_score\n",
    "print(\"The spam score of the article headline is \", spam_score(header))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae8271e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def source_reliability_score(content):\n",
    "    with open('models/srcM.pkl', 'rb') as f:\n",
    "        srcM = pickle.load(f)\n",
    "    pred_labels = []\n",
    "    for paragraph in content:\n",
    "        label = srcM.predict_text(paragraph)[0]\n",
    "        pred_labels.append(label)\n",
    "    return np.mean(pred_labels)\n",
    "print(\"The source reliability score of the article is \", source_reliability_score(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a930a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def clickbait_score(header):\n",
    "    with open('models/clickM.pkl', 'rb') as f:\n",
    "        clickM = pickle.load(f)\n",
    "    label, proba = clickM.predict_text(header)\n",
    "    return label[0]\n",
    "print(\"The clickbait score of the article is \", clickbait_score(header))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
