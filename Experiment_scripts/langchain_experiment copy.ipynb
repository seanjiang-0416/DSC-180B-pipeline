{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import (\n",
    "    ChatGoogleGenerativeAI,\n",
    "    HarmBlockThreshold,\n",
    "    HarmCategory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import wikipedia\n",
    "from nltk.tokenize import sent_tokenize\n",
    "#import tensorflow_hub as hub\n",
    "import spacy\n",
    "import nltk\n",
    "from scipy import spatial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "safety_settings = [\n",
    "    {\n",
    "        \"category\": \"HARM_CATEGORY_DANGEROUS\",\n",
    "        \"threshold\": \"BLOCK_NONE\",\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
    "        \"threshold\": \"BLOCK_NONE\",\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
    "        \"threshold\": \"BLOCK_NONE\",\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
    "        \"threshold\": \"BLOCK_NONE\",\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
    "        \"threshold\": \"BLOCK_NONE\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", \n",
    "google_api_key=\"removed\", \n",
    "                            safety_settings={\n",
    "        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evidence retrieval with Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wiki_search(text):\n",
    "    try:\n",
    "        page = wikipedia.page(text, auto_suggest=False)\n",
    "    except wikipedia.DisambiguationError as e:\n",
    "        sel = e.options[0]\n",
    "        page = wikipedia.page(sel)\n",
    "        \n",
    "    return page.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/orenciolli/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /Users/orenciolli/anaconda3/lib/python3.11/site-packages (from en-core-web-sm==3.7.1) (3.7.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/orenciolli/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/orenciolli/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/orenciolli/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/orenciolli/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/orenciolli/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /Users/orenciolli/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.3)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/orenciolli/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/orenciolli/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/orenciolli/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /Users/orenciolli/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /Users/orenciolli/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/orenciolli/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (5.2.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/orenciolli/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.65.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/orenciolli/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/orenciolli/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.10.8)\n",
      "Requirement already satisfied: jinja2 in /Users/orenciolli/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /Users/orenciolli/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (68.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/orenciolli/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (23.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/orenciolli/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /Users/orenciolli/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.24.3)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/orenciolli/anaconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/orenciolli/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/orenciolli/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/orenciolli/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/orenciolli/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2023.7.22)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/orenciolli/anaconda3/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/orenciolli/anaconda3/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/orenciolli/anaconda3/lib/python3.11/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.0.4)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /Users/orenciolli/anaconda3/lib/python3.11/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/orenciolli/anaconda3/lib/python3.11/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.1)\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.7.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n"
     ]
    }
   ],
   "source": [
    "spacy.cli.download(\"en_core_web_sm\")\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel, pipeline\n",
    "\n",
    "def text_embedding(data):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    bert_model = BertModel.from_pretrained('bert-base-uncased').to(device)\n",
    "    \n",
    "    def get_bert_embeddings(data):\n",
    "        tokens = tokenizer(data.tolist(), padding=True, truncation=True, return_tensors='pt').to(device)\n",
    "        with torch.no_grad():\n",
    "            embeddings = bert_model(**tokens).last_hidden_state.mean(dim=1)\n",
    "        return embeddings\n",
    "\n",
    "    batch_size = 128\n",
    "    num_samples = len(data)\n",
    "    num_batches = (num_samples + batch_size - 1) // batch_size\n",
    "\n",
    "    embeddings_list = []\n",
    "\n",
    "    for i in range(num_batches):\n",
    "        start_idx = i * batch_size\n",
    "        end_idx = (i + 1) * batch_size\n",
    "        batch_data = data.iloc[start_idx:end_idx]\n",
    "        batch_embeddings = get_bert_embeddings(batch_data)\n",
    "        embeddings_list.append(batch_embeddings)\n",
    "\n",
    "    embeddings = torch.cat(embeddings_list, dim=0).cpu().numpy()\n",
    "    return embeddings\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entities(text):\n",
    "    doc = nlp(text)\n",
    "    entities = [ent.text for ent in doc.ents]\n",
    "    return entities\n",
    "    \n",
    "def retrieve_documents(claim):\n",
    "    docs = []\n",
    "    entities = get_entities(claim)\n",
    "    \n",
    "    for entity in entities:\n",
    "        docs.append(wiki_search(entity))\n",
    "    return docs\n",
    "\n",
    "def compute_similarity(sentence1, sentence2):\n",
    "    \n",
    "    data = pd.Series([sentence1, sentence2])\n",
    "    embed = text_embedding(data)\n",
    "    \n",
    "    embedding1 = embed[0]\n",
    "    embedding2 = embed[1]\n",
    "\n",
    "    # Compute the cosine similarity between the two sentence embeddings\n",
    "    similarity = 1 - spatial.distance.cosine(embedding1, embedding2)\n",
    "\n",
    "    return similarity\n",
    "\n",
    "def top_k_sentences(claim, split_sentences, k):\n",
    "    sims = []\n",
    "    \n",
    "    for sentence in split_sentences: \n",
    "        sims.append((sentence, compute_similarity(sentence, claim)))\n",
    "\n",
    "        #also post to db?\n",
    "\n",
    "    sims = sorted(sims, key=lambda x: x[1], reverse = True)\n",
    "    return [elem[0] for elem in sims[:k]]\n",
    "\n",
    "def get_wiki_evidence(claim, k):\n",
    "    docs = retrieve_documents(claim)\n",
    "    evidence = []\n",
    "    \n",
    "    for doc in docs:\n",
    "        sentences = sent_tokenize(doc)\n",
    "        evidence += top_k_sentences(claim, sentences, k)\n",
    "        \n",
    "    return evidence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joe Biden\n",
      "COVID\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m get_wiki_evidence(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJoe Biden created COVID\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n",
      "Cell \u001b[0;32mIn[31], line 45\u001b[0m, in \u001b[0;36mget_wiki_evidence\u001b[0;34m(claim, k)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m docs:\n\u001b[1;32m     44\u001b[0m     sentences \u001b[38;5;241m=\u001b[39m sent_tokenize(doc)\n\u001b[0;32m---> 45\u001b[0m     evidence \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m top_k_sentences(claim, sentences, k)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m evidence\n",
      "Cell \u001b[0;32mIn[31], line 32\u001b[0m, in \u001b[0;36mtop_k_sentences\u001b[0;34m(claim, split_sentences, k)\u001b[0m\n\u001b[1;32m     29\u001b[0m sims \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m split_sentences: \n\u001b[0;32m---> 32\u001b[0m     sims\u001b[38;5;241m.\u001b[39mappend((sentence, compute_similarity(sentence, claim)))\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m#also post to db?\u001b[39;00m\n\u001b[1;32m     36\u001b[0m sims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(sims, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m1\u001b[39m], reverse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[31], line 18\u001b[0m, in \u001b[0;36mcompute_similarity\u001b[0;34m(sentence1, sentence2)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_similarity\u001b[39m(sentence1, sentence2):\n\u001b[1;32m     17\u001b[0m     data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries([sentence1, sentence2])\n\u001b[0;32m---> 18\u001b[0m     embed \u001b[38;5;241m=\u001b[39m text_embedding(data)\n\u001b[1;32m     20\u001b[0m     embedding1 \u001b[38;5;241m=\u001b[39m embed[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     21\u001b[0m     embedding2 \u001b[38;5;241m=\u001b[39m embed[\u001b[38;5;241m1\u001b[39m]\n",
      "Cell \u001b[0;32mIn[26], line 6\u001b[0m, in \u001b[0;36mtext_embedding\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtext_embedding\u001b[39m(data):\n\u001b[1;32m      5\u001b[0m     device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m BertTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbert-base-uncased\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m     bert_model \u001b[38;5;241m=\u001b[39m BertModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbert-base-uncased\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_bert_embeddings\u001b[39m(data):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1813\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1811\u001b[0m             resolved_vocab_files[file_id] \u001b[38;5;241m=\u001b[39m download_url(file_path, proxies\u001b[38;5;241m=\u001b[39mproxies)\n\u001b[1;32m   1812\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1813\u001b[0m         resolved_vocab_files[file_id] \u001b[38;5;241m=\u001b[39m cached_file(\n\u001b[1;32m   1814\u001b[0m             pretrained_model_name_or_path,\n\u001b[1;32m   1815\u001b[0m             file_path,\n\u001b[1;32m   1816\u001b[0m             cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[1;32m   1817\u001b[0m             force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[1;32m   1818\u001b[0m             proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[1;32m   1819\u001b[0m             resume_download\u001b[38;5;241m=\u001b[39mresume_download,\n\u001b[1;32m   1820\u001b[0m             local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m   1821\u001b[0m             token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[1;32m   1822\u001b[0m             user_agent\u001b[38;5;241m=\u001b[39muser_agent,\n\u001b[1;32m   1823\u001b[0m             revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[1;32m   1824\u001b[0m             subfolder\u001b[38;5;241m=\u001b[39msubfolder,\n\u001b[1;32m   1825\u001b[0m             _raise_exceptions_for_missing_entries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1826\u001b[0m             _raise_exceptions_for_connection_errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1827\u001b[0m             _commit_hash\u001b[38;5;241m=\u001b[39mcommit_hash,\n\u001b[1;32m   1828\u001b[0m         )\n\u001b[1;32m   1829\u001b[0m         commit_hash \u001b[38;5;241m=\u001b[39m extract_commit_hash(resolved_vocab_files[file_id], commit_hash)\n\u001b[1;32m   1831\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(unresolved_files) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/utils/hub.py:428\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    425\u001b[0m user_agent \u001b[38;5;241m=\u001b[39m http_user_agent(user_agent)\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    427\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 428\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m hf_hub_download(\n\u001b[1;32m    429\u001b[0m         path_or_repo_id,\n\u001b[1;32m    430\u001b[0m         filename,\n\u001b[1;32m    431\u001b[0m         subfolder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(subfolder) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m subfolder,\n\u001b[1;32m    432\u001b[0m         repo_type\u001b[38;5;241m=\u001b[39mrepo_type,\n\u001b[1;32m    433\u001b[0m         revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[1;32m    434\u001b[0m         cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[1;32m    435\u001b[0m         user_agent\u001b[38;5;241m=\u001b[39muser_agent,\n\u001b[1;32m    436\u001b[0m         force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[1;32m    437\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[1;32m    438\u001b[0m         resume_download\u001b[38;5;241m=\u001b[39mresume_download,\n\u001b[1;32m    439\u001b[0m         token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[1;32m    440\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m    441\u001b[0m     )\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    443\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    444\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to access a gated repo.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMake sure to request access at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    445\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and pass a token having permission to this repo either \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    446\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mby logging in with `huggingface-cli login` or by passing `token=<your_token>`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    447\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    116\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1195\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout)\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1194\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m         metadata \u001b[38;5;241m=\u001b[39m get_hf_file_metadata(\n\u001b[1;32m   1196\u001b[0m             url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m   1197\u001b[0m             token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[1;32m   1198\u001b[0m             proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[1;32m   1199\u001b[0m             timeout\u001b[38;5;241m=\u001b[39metag_timeout,\n\u001b[1;32m   1200\u001b[0m         )\n\u001b[1;32m   1201\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n\u001b[1;32m   1202\u001b[0m         \u001b[38;5;66;03m# Cache the non-existence of the file and raise\u001b[39;00m\n\u001b[1;32m   1203\u001b[0m         commit_hash \u001b[38;5;241m=\u001b[39m http_error\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(HUGGINGFACE_HEADER_X_REPO_COMMIT)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    116\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1532\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout)\u001b[0m\n\u001b[1;32m   1529\u001b[0m headers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccept-Encoding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124midentity\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# prevent any compression => we want to know the real size of the file\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[0;32m-> 1532\u001b[0m r \u001b[38;5;241m=\u001b[39m _request_wrapper(\n\u001b[1;32m   1533\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHEAD\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1534\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m   1535\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m   1536\u001b[0m     allow_redirects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1537\u001b[0m     follow_relative_redirects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   1538\u001b[0m     proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[1;32m   1539\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m   1540\u001b[0m )\n\u001b[1;32m   1541\u001b[0m hf_raise_for_status(r)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;66;03m# Return\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:407\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, max_retries, base_wait_time, max_wait_time, timeout, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;66;03m# 2. Force relative redirection\u001b[39;00m\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[0;32m--> 407\u001b[0m     response \u001b[38;5;241m=\u001b[39m _request_wrapper(\n\u001b[1;32m    408\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    409\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m    410\u001b[0m         max_retries\u001b[38;5;241m=\u001b[39mmax_retries,\n\u001b[1;32m    411\u001b[0m         base_wait_time\u001b[38;5;241m=\u001b[39mbase_wait_time,\n\u001b[1;32m    412\u001b[0m         max_wait_time\u001b[38;5;241m=\u001b[39mmax_wait_time,\n\u001b[1;32m    413\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m    414\u001b[0m         follow_relative_redirects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    415\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    416\u001b[0m     )\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[1;32m    419\u001b[0m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n\u001b[1;32m    420\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m300\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m399\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:442\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, max_retries, base_wait_time, max_wait_time, timeout, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n\u001b[1;32m    441\u001b[0m \u001b[38;5;66;03m# 3. Exponential backoff\u001b[39;00m\n\u001b[0;32m--> 442\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m http_backoff(\n\u001b[1;32m    443\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    444\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m    445\u001b[0m     max_retries\u001b[38;5;241m=\u001b[39mmax_retries,\n\u001b[1;32m    446\u001b[0m     base_wait_time\u001b[38;5;241m=\u001b[39mbase_wait_time,\n\u001b[1;32m    447\u001b[0m     max_wait_time\u001b[38;5;241m=\u001b[39mmax_wait_time,\n\u001b[1;32m    448\u001b[0m     retry_on_exceptions\u001b[38;5;241m=\u001b[39m(ConnectTimeout, ProxyError),\n\u001b[1;32m    449\u001b[0m     retry_on_status_codes\u001b[38;5;241m=\u001b[39m(),\n\u001b[1;32m    450\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    452\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/huggingface_hub/utils/_http.py:212\u001b[0m, in \u001b[0;36mhttp_backoff\u001b[0;34m(method, url, max_retries, base_wait_time, max_wait_time, retry_on_exceptions, retry_on_status_codes, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mseek(io_obj_initial_pos)\n\u001b[1;32m    211\u001b[0m \u001b[38;5;66;03m# Perform request and return if status_code is not in the retry list.\u001b[39;00m\n\u001b[0;32m--> 212\u001b[0m response \u001b[38;5;241m=\u001b[39m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m retry_on_status_codes:\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    483\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[1;32m    487\u001b[0m         method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    488\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m    489\u001b[0m         body\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mbody,\n\u001b[1;32m    490\u001b[0m         headers\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    491\u001b[0m         redirect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    492\u001b[0m         assert_same_host\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    493\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    494\u001b[0m         decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    495\u001b[0m         retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries,\n\u001b[1;32m    496\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m    497\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[1;32m    498\u001b[0m     )\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py:714\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    713\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 714\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[1;32m    715\u001b[0m     conn,\n\u001b[1;32m    716\u001b[0m     method,\n\u001b[1;32m    717\u001b[0m     url,\n\u001b[1;32m    718\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[1;32m    719\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[1;32m    720\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m    721\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[1;32m    722\u001b[0m )\n\u001b[1;32m    724\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    725\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    726\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n\u001b[1;32m    728\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py:466\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    461\u001b[0m             httplib_response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m    462\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    463\u001b[0m             \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    464\u001b[0m             \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    465\u001b[0m             \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 466\u001b[0m             six\u001b[38;5;241m.\u001b[39mraise_from(e, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py:461\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    459\u001b[0m     \u001b[38;5;66;03m# Python 3\u001b[39;00m\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 461\u001b[0m         httplib_response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m    462\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    463\u001b[0m         \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    464\u001b[0m         \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    465\u001b[0m         \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m    466\u001b[0m         six\u001b[38;5;241m.\u001b[39mraise_from(e, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/http/client.py:1378\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1376\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1377\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1378\u001b[0m         response\u001b[38;5;241m.\u001b[39mbegin()\n\u001b[1;32m   1379\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1380\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_status()\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv_into(b)\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/ssl.py:1311\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1307\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1308\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1309\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1310\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(nbytes, buffer)\n\u001b[1;32m   1312\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/ssl.py:1167\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1165\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1167\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1168\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1169\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "get_wiki_evidence('Joe Biden created COVID', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_claim(claim):\n",
    "\n",
    "    #articles = get_article_evidence(claim)\n",
    "#     ground_truth = get_wiki_evidence(claim)\n",
    "\n",
    "#todo: add ground truth\n",
    "\n",
    "\n",
    "    prompt = f\"\"\" \n",
    "    Here are some examples of some claims and their veracity classifications on a scale of from 0 to 5,\n",
    "    with 0 being completely true and 5 being entirely false, with brief justification:\n",
    "    \n",
    "    Claim 1: 'Hillary Clinton in 2005 co-sponsored legislation that would jail flag burners.'\n",
    "    Classification 1: '0. This claim is 0 (True) because Hillary Clinton co-sponsored legislation in 2005 that would jail flag burners.'\n",
    "    \n",
    "    Claim 2: ''On military recruiters at Harvard, Elena Kagan took a position and the Supreme Court ruled unanimously that she was wrong.'\n",
    "    Classification 2: '0. This claim is 0 (True) because the court did  reject the arguments put forward by the law schools, \n",
    "    which included FAIR  and the brief filed by the Harvard professors. All of the justices who voted opposed the law schools arguments'\n",
    "    \n",
    "    Claim 3: 'Have the suburbs been inundated with former residents of Atlanta housing projects? Absolutely not.'\n",
    "    Classification 3: 'DeKalb Countys population is slightly more than 747,000, the Census Bureau data show.\n",
    "    The data from the AHA and Georgia State both reach similar conclusions that the percentage of tenants moving out of the city has been small.'\n",
    "    \n",
    "    Claim 4: 'Under legislation that has cleared the Georgia House, some children who are legal refugees \n",
    "    could obtain state scholarships to attend private schools.'\n",
    "    Classification 4: '0. This claim is 0(True) because legislation has cleared the Georgia House that would expand the list of students eligible for a \n",
    "    private school scholarship program created in 2007. The scholarships are now offered in varying amounts to students with disabilities.\n",
    "    The bill would open the program to about 700 legal refugees who are not proficient in English.'\n",
    "    \n",
    "    \n",
    "    Claim 5: 'Hillary Clinton agrees with John McCain by voting to give George Bush the benefit of the doubt on Iran.'\n",
    "    Classification 5: '1. This claim is 1 (mostly true). Although Clinton may have \"agreed\" with McCain on the issue, they did not technically vote the same way on it. \n",
    "    To say that voting for Kyl-Lieberman is giving George Bush the benefit of the doubt on Iran remains a contentious issue. But Obamas main point is that Clinton and McCain \n",
    "    were on the same side, and that is correct.'\n",
    "    \n",
    "    Claim 6: 'Mark Pryor votes with Obama 93 percent of the time.'\n",
    "    Classification 6: '1. This claim is 1 (mostly true) because Since Obama became president, Pryor has voted in line with the \n",
    "    presidents positions between 90 and 95 percent of the time, with 92. 6 percent -- basically 93 percent -- as the average, \n",
    "    according to the best rating system at our disposal. Pryor doesnt vote with the Democratic Party quite as often, though, \n",
    "    and in 2013 his presidential support votes were lower than every other Senate Democrat. Cottons number is on target based on \n",
    "    the data, but Pryor has also opposed Obama on a few key issues.'\n",
    "    \n",
    "    Claim 7: 'Hillary Clinton said the Veterans Affairs scandal is over-exaggerated. She said she was satisfied with what was going on.'\n",
    "    Classification 7: 'This claim is 3 (barely true) because while Clinton has said problems at the VA have not been as widespread as it has been made out to be,\n",
    "    she has also acknowledged systemic problems within the system and repeatedly urged reform so veterans can get care quickly.'\n",
    "    \n",
    "    \n",
    "    Claim 8: 'the paperback edition of Mitt Romneys book deleted line that Massachusetts individual mandate should be the model for the country'\n",
    "    Classification 8: '3. This claim is 3 (barely true) because Perry's right that Romney's comments about health care were edited between editions. Among other things, \n",
    "    a line that advocated the Massachusetts model as a strong option for other states was replaced by a shorter, more generic sentence. But that line was preceded\n",
    "    by an argument for state-level solutions, exactly the argument Romney extends now. That's not how Perry characterized it.'\n",
    "    \n",
    "    Claim 9: 'This year in Congress Connie Mack IV has missed almost half of his votes.'\n",
    "    Classification 9: '3. This claim is 3 (barely true) because Mack has more votes than the average member of\n",
    "    the U. S.  House of Representatives, and hes missed high-profile votes on health care and the budget. He hasnt missed almost half of his votes, though.'\n",
    "    \n",
    "    Claim 10: 'Numerous studies have shown that these so-called right-to-work laws do not generate jobs and economic growth.'\n",
    "    Classification 10: '2. This claim is 2 (half true) because Right-to-work states have seen greater job increases, but one economist pointed out that such a dynamic doesnt prove\n",
    "    right-to-work laws were the cause. Another professor who believes job growth results from right-to-work laws acknowledged that many other factors also could be responsible.'\n",
    "    \n",
    "    Claim 11: 'When did the decline of coal start? It started when natural gas took off that started to begin in President George W. Bushs administration.'\n",
    "    Classification 11: '2. This claim is 2 (half true) because there is no doubt, natural gas has been gaining ground on coal in generating electricity. \n",
    "    The trend started in the 1990s but clearly gained speed during the Bush administration when the production of natural gas -- a competitor of coal -- picked up. \n",
    "    But analysts give little credit or blame to Bush for that trend. They note that other factors, such as technological innovation, entrepreneurship and\n",
    "    policies of previous administrations, had more to do with laying the groundwork for the natural gas boom.'\n",
    "    \n",
    "    Claim 12: 'Of Virginias 98,000 teachers who are K-12, over 53,000 of those teachers today are over 50 years old.'\n",
    "    Classification 12: '4. This claim is 4 (false) because Virginia does not keep data that is solely focused on the age of teachers. The best statistics available show that the states \n",
    "    instructional staff -- including teachers, librarians, guidance counselors and technology instructors -- was 98,792 during the 2010-11 school year and, of them, 33,462 were 50 or older.\n",
    "    The teaching corps is not moving toward retirement with anything close to the speed described.'\n",
    "    \n",
    "    Claim 13: 'What the Obama administration is going to come out with in the next several months is youre not even going to be able to burn coal very \n",
    "    limitedly in the existing plants.'\n",
    "    Classification 13: '4. This claim is 4 (false) because The proposal the claim is referring to is an EPA plan to cut carbon emissions in existing power plants. Those rules do not prohibit \n",
    "    current facilities from burning coal, and even Capitos spokeswoman said the rule doesnt mean that every plant has to close. Some facilities will close down within the next decade, \n",
    "    but many of those plants were scheduled to be retired anyway due to age and other factors. States and power companies have options to continue to utilize coal for energy, and experts said \n",
    "    they expect coal to remain part of the national portfolio for years to come.'\n",
    "    \n",
    "    Claim 14: 'Charlie Crist supports cuts to the Medicare Advantage program.'\n",
    "    Classification 14: '4. This claim is 4 (false) because Crist has flip-flopped on a lot of issues, including the federal health care law. He used to oppose the Affordable Care Act, \n",
    "    but now he supports it. The law tries to bring down future health care costs by reducing Medicare Advantage payments. But on the issue of Medicare Advantage, Crist has actually been\n",
    "    consistent: Hes been critical of the Medicare Advantage cuts for years. He specifically said he opposed the reductions in 2009 and 2010, and he \n",
    "    still opposes them today. Crist doesnt appear to have come up with other ways to save money on health care without reducing payments to Medicare Advantage.'\n",
    "    \n",
    "    Claim 15: 'Says Ohio budget item later signed into law by Gov. John Kasich requires women seeking an abortion to undergo a mandatory vaginal probe.'\n",
    "    Classification 15: '5. This claim is 5 (entirely false/fabricated) because there should be no debate about what types of ultrasounds these new regulations require. there is a mandate \n",
    "    -- but for external detection methods.'\n",
    "    \n",
    "    Claim 16: 'Roughly 25% of RI has a criminal record'\n",
    "    Classification 16: '5. This claim is 5 (entirely false/fabricated) because They cant be sure of the exact percentage because of the way the data is collected, but theyre certain its nowhere near 25 percent. \n",
    "    DAREs statement is based on old, flawed statistics that were tweaked and re-tweaked to make a point.'\n",
    "    \n",
    "    Claim 17: 'We spend less on defense today as percentage of GDP than at any time since Pearl Harbor.'\n",
    "    Classification 17: '5. This claim is 5 (entirely false/fabricated) because since the Cold War ended, and in a few other years as well, the percent of GDP used for defense has been consistently lower \n",
    "    than current spending levels.'\n",
    "    \n",
    "    Please rate the veracity of the following claim on the same 0 to 5 scale. Ensure that the first character \n",
    "    in your response is a single integer between 0 and 5, and explain your reasoning like the examples above, citing\n",
    "    any evidence in a chain of thought fashion. {claim} \n",
    "   \n",
    "    \"\"\"\n",
    "\n",
    "    response = llm.invoke(prompt).content\n",
    "\n",
    "    rating = response[0]\n",
    "\n",
    "    return response, int(rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIAR evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('liar_plus/test2.tsv', delimiter='\\t', header = None)\n",
    "\n",
    "df = df.drop(columns = [0])\n",
    "df.rename({1: 'id', 2: 'label', 3: 'statement', 4: 'subject', 5: 'speaker', 6: 'job-title',\n",
    "           7: 'state_info', 8: 'party_affiliation', 9: 'barely_true_counts', 10: 'false_counts',\n",
    "           11: 'half_true_counts', 12: 'mostly_true_counts', 13: 'pants_on_fire_counts', 14: 'context',\n",
    "           15: 'justification'\n",
    "          }, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {'pants-fire': 5, 'false': 4, 'barely-true': 3, \n",
    "             'half-true': 2, 'mostly-true': 1, 'true': 0}\n",
    "\n",
    "df['label'] = df['label'].replace(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preds = df['statement'].apply(lambda x: evaluate_claim(x)[1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1267it [1:51:53,  5.30s/it]\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "justs = []\n",
    "labels = []\n",
    "\n",
    "for index, row in tqdm(df.iterrows()):\n",
    "    try:\n",
    "        justification, result = evaluate_claim(row['statement'])\n",
    "\n",
    "        preds.append(result)\n",
    "        labels.append(row['label'])\n",
    "        justs.append(justification)\n",
    "        \n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23052208835341365"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame({'predicted': preds, 'label': labels, 'justification': justs})\n",
    "\n",
    "results_df['predicted'] = results_df['predicted'].astype(int)\n",
    "(results_df['predicted'] == results_df['label']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Building a wall on the U.S.-Mexico border will take literally years.'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['statement'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('0\\nBuilding a wall on the U.S.-Mexico border is a complex and time-consuming project that would take years to complete. According to experts, the construction of a wall along the entire U.S.-Mexico border would take at least 3.5 years and cost billions of dollars.',\n",
       " 0)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_claim(df['statement'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predicted    object\n",
       "label         int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5124584717607974"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(abs(results_df['predicted'].astype(int) - results_df['label'].astype(int)) <= 1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7812ea015bdcee6f23a998adcdd2ef97c151c0c241b7b7070987d9313e41299d"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}